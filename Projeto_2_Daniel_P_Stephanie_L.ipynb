{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Daniel Pucciariello\n",
    "\n",
    "Nome: Stephanie Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@datascience_terradonunca***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'pastel'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 550\n",
    "\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 350\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"pastel.xlsx\")\n",
    "data2 = pd.read_excel(\"pastel1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_repeticao = set(data.Treinamento)\n",
    "s_repeticao2 = set(data2.Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(list(s_repeticao))\n",
    "series2 = pd.Series(list(s_repeticao2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.concat([series,series2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_excel('Treinamento.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open Treinamento.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_excel(\"pastel1.xlsx\",sheet_name=\"Treinamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \" \".join(data3[data3.Classe<=1].Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pastel                     0.054259\n",
       "de                         0.045179\n",
       "e                          0.025724\n",
       "a                          0.023779\n",
       "eu                         0.023346\n",
       "um                         0.021401\n",
       "rt                         0.017942\n",
       "o                          0.017077\n",
       "comer                      0.012105\n",
       "pra                        0.011673\n",
       "com                        0.011241\n",
       "da                         0.010592\n",
       "que                        0.010592\n",
       "mas                        0.010160\n",
       "em                         0.009295\n",
       "do                         0.009295\n",
       "tô                         0.008214\n",
       "gente                      0.007998\n",
       "já                         0.007566\n",
       "na                         0.007566\n",
       "é                          0.007134\n",
       "só                         0.006917\n",
       "falando                    0.006701\n",
       "vcs                        0.006485\n",
       "também                     0.006485\n",
       "sensação                   0.006269\n",
       "relação                    0.006269\n",
       "sozinhos?,                 0.006269\n",
       "feira                      0.006269\n",
       "uma                        0.006269\n",
       "                             ...   \n",
       "vocês!                     0.000216\n",
       "uniao                      0.000216\n",
       "sim)                       0.000216\n",
       "https://t.co/putfm6yfj4    0.000216\n",
       "@uttpcyeol:                0.000216\n",
       "ngm                        0.000216\n",
       "daqueles                   0.000216\n",
       "@j4dde_                    0.000216\n",
       "@empolguei                 0.000216\n",
       "https://t.co/kpl0yxbi4t    0.000216\n",
       "gostosas                   0.000216\n",
       "deus!                      0.000216\n",
       "@bwrntdiee:                0.000216\n",
       "dando                      0.000216\n",
       "@edupadelista              0.000216\n",
       "old                        0.000216\n",
       "chata,                     0.000216\n",
       "aguento                    0.000216\n",
       "diz                        0.000216\n",
       "jatinho                    0.000216\n",
       "loka,                      0.000216\n",
       "feira,                     0.000216\n",
       "haha                       0.000216\n",
       "daquele                    0.000216\n",
       "desejo                     0.000216\n",
       "garota                     0.000216\n",
       "hj,                        0.000216\n",
       "cruzeiro,                  0.000216\n",
       "oq                         0.000216\n",
       "sempre)                    0.000216\n",
       "Length: 1345, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(s.lower().split()).value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      \"tu quer comer pastel?\"\\nmeu pai chamando minh...\n",
       "1      \"vem comer pastel amor, a sobremesa é o seu do...\n",
       "2      [5/9 00:57] juliaa: paga o pastel\\n[5/9 00:58]...\n",
       "3                       @_magrela__ vou comer pastel sim\n",
       "4      @1640ginnie está com o que? estou bem!!!!! com...\n",
       "5      @ahsuashaushauhs bo fazer uns pastel na minha ...\n",
       "6                  @alinnefanelli e quem resiste pastel?\n",
       "7      @alinnefanelli quero ver o pastel da feira com...\n",
       "8      @alinnefanelli toda semana?! vocês não querem ...\n",
       "9      @bomdia_sp a feira de salesopolis tem muito ma...\n",
       "10       @caio_luis26 saudades de ir com vc comer pastel\n",
       "11                @edupadelista pastel de nata? bom dia!\n",
       "12                @ferigatto_gui vc não vai comer pastel\n",
       "13                       @fp_nike aí já é frança, pastel\n",
       "14     @g1sptv bom dia. feiras de rua tem que ter \"pa...\n",
       "15                  @geragerencia amiga tem pastel doce?\n",
       "16     @gerardot3ixeira uma pena o fato de demorar um...\n",
       "17     @guilhotinaaa vamo marcar um dia de comer um p...\n",
       "18     @gustavo66251419 aula tá chata, só lendo sobre...\n",
       "19     @iasminleao_ o pastel eu não tenho, mas a cala...\n",
       "20     @igorsenna97 eu paguei 13 num pastel minúsculo...\n",
       "21     @isecrf @empolguei domingo de manhã, eu levant...\n",
       "22     @iviescopel caaaaaaaaaaaaaara! hj é quinta! di...\n",
       "23     @jesmaciel @heitor147 eu ainda ia meter em esp...\n",
       "24     @joaopaulomf_ zerou a savassi gad kkkkkkkkk ma...\n",
       "25     @joomede79149855 tipo uma pastel e um caldo de...\n",
       "26     @lolozita17 muito pastel kkkkkk\\nagr bobagem s...\n",
       "27     @loremattitas @hiegofelipe nada de novo né, ca...\n",
       "28     @lucasalx97 to vendo mais sua mãe do que você ...\n",
       "29                        @lucaszampiva1 pastel de chuva\n",
       "                             ...                        \n",
       "270               se tem uma coisa que eu gosto é pastel\n",
       "271    sempre que saio do treino apetece-me pastel de...\n",
       "272    sério, o de eu arranjo um pastel e uma pepsi a...\n",
       "273          só pelo meu pastel😋 https://t.co/putfm6yfj4\n",
       "274     só por desaforo vo bolar um pastel aq 🤤 kkkkkkkk\n",
       "275    só pq eu fiz a maior propaganda do pastel pra ...\n",
       "276    só queria comer 4 açaí, 8 coxinha e 5 pastel c...\n",
       "277    só queria ir na escola pra depois sair e come ...\n",
       "278          só queria um pastel com caldo de cana agora\n",
       "279    so queria um pastel de frango com cheddar e mo...\n",
       "280    só quero um caldo de cana de 500ml, um pastel ...\n",
       "281    tentando entender pq eu comprei pipoca doce no...\n",
       "282    tfw ngm pra dormir cmg na sexta, acordar no sá...\n",
       "283    tô com uma vontade de comer pastel de carne co...\n",
       "284                   tô doida pra comer um pastel pqp 🤤\n",
       "285    tô na esperança de mamãe ir na feira e trazer ...\n",
       "286    tô nem entendendo essa vontade sendo que nem g...\n",
       "287                          todo mundo trouxe pastel hj\n",
       "288    tomei meu cafezinho com pastel, agora pode com...\n",
       "289    tudo que eu comi o dia todo hj foi um pastel c...\n",
       "290    uma tentação do cacete aqui em casa, to parand...\n",
       "291                        vai ter pastel pra lau amanhã\n",
       "292            vei vontade de comer um pastel de 1 metro\n",
       "293    vi o vídeo da @nilmoretto comendo pastel e agr...\n",
       "294    vo só toma uma bera e vê o jogo.\\n\\n03:21 come...\n",
       "295               vou agitar o pastel essa hora da manhã\n",
       "296    vou comer um pastel de frango com catupiry, nã...\n",
       "297    vou flr cm vc lá no pastel no sábado — mds e q...\n",
       "298    vulneravel e fragilizado precisando comprar um...\n",
       "299                            ws ta vendendo pastel 🤣🤣🤣\n",
       "Name: Treinamento, Length: 300, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.Treinamento.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-fa27b327dabf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "data4 = cleanup(data3.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
