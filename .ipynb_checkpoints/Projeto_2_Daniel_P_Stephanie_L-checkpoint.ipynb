{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Daniel Pucciariello\n",
    "\n",
    "Nome: Stephanie Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@datascience_terradonunca***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'pastel'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 550\n",
    "\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 350\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa √© manual. Fa√ßa a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"pastel.xlsx\")\n",
    "data2 = pd.read_excel(\"pastel1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_repeticao = set(data.Treinamento)\n",
    "s_repeticao2 = set(data2.Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(list(s_repeticao))\n",
    "series2 = pd.Series(list(s_repeticao2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.concat([series,series2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_excel('Treinamento.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open Treinamento.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_excel(\"pastel1.xlsx\",sheet_name=\"Treinamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \" \".join(data3[data3.Classe<=1].Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pastel                     0.054259\n",
       "de                         0.045179\n",
       "e                          0.025724\n",
       "a                          0.023779\n",
       "eu                         0.023346\n",
       "um                         0.021401\n",
       "rt                         0.017942\n",
       "o                          0.017077\n",
       "comer                      0.012105\n",
       "pra                        0.011673\n",
       "com                        0.011241\n",
       "da                         0.010592\n",
       "que                        0.010592\n",
       "mas                        0.010160\n",
       "em                         0.009295\n",
       "do                         0.009295\n",
       "t√¥                         0.008214\n",
       "gente                      0.007998\n",
       "j√°                         0.007566\n",
       "na                         0.007566\n",
       "√©                          0.007134\n",
       "s√≥                         0.006917\n",
       "falando                    0.006701\n",
       "vcs                        0.006485\n",
       "tamb√©m                     0.006485\n",
       "sensa√ß√£o                   0.006269\n",
       "rela√ß√£o                    0.006269\n",
       "sozinhos?,                 0.006269\n",
       "feira                      0.006269\n",
       "uma                        0.006269\n",
       "                             ...   \n",
       "voc√™s!                     0.000216\n",
       "uniao                      0.000216\n",
       "sim)                       0.000216\n",
       "https://t.co/putfm6yfj4    0.000216\n",
       "@uttpcyeol:                0.000216\n",
       "ngm                        0.000216\n",
       "daqueles                   0.000216\n",
       "@j4dde_                    0.000216\n",
       "@empolguei                 0.000216\n",
       "https://t.co/kpl0yxbi4t    0.000216\n",
       "gostosas                   0.000216\n",
       "deus!                      0.000216\n",
       "@bwrntdiee:                0.000216\n",
       "dando                      0.000216\n",
       "@edupadelista              0.000216\n",
       "old                        0.000216\n",
       "chata,                     0.000216\n",
       "aguento                    0.000216\n",
       "diz                        0.000216\n",
       "jatinho                    0.000216\n",
       "loka,                      0.000216\n",
       "feira,                     0.000216\n",
       "haha                       0.000216\n",
       "daquele                    0.000216\n",
       "desejo                     0.000216\n",
       "garota                     0.000216\n",
       "hj,                        0.000216\n",
       "cruzeiro,                  0.000216\n",
       "oq                         0.000216\n",
       "sempre)                    0.000216\n",
       "Length: 1345, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(s.lower().split()).value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      \"tu quer comer pastel?\"\\nmeu pai chamando minh...\n",
       "1      \"vem comer pastel amor, a sobremesa √© o seu do...\n",
       "2      [5/9 00:57] juliaa: paga o pastel\\n[5/9 00:58]...\n",
       "3                       @_magrela__ vou comer pastel sim\n",
       "4      @1640ginnie est√° com o que? estou bem!!!!! com...\n",
       "5      @ahsuashaushauhs bo fazer uns pastel na minha ...\n",
       "6                  @alinnefanelli e quem resiste pastel?\n",
       "7      @alinnefanelli quero ver o pastel da feira com...\n",
       "8      @alinnefanelli toda semana?! voc√™s n√£o querem ...\n",
       "9      @bomdia_sp a feira de salesopolis tem muito ma...\n",
       "10       @caio_luis26 saudades de ir com vc comer pastel\n",
       "11                @edupadelista pastel de nata? bom dia!\n",
       "12                @ferigatto_gui vc n√£o vai comer pastel\n",
       "13                       @fp_nike a√≠ j√° √© fran√ßa, pastel\n",
       "14     @g1sptv bom dia. feiras de rua tem que ter \"pa...\n",
       "15                  @geragerencia amiga tem pastel doce?\n",
       "16     @gerardot3ixeira uma pena o fato de demorar um...\n",
       "17     @guilhotinaaa vamo marcar um dia de comer um p...\n",
       "18     @gustavo66251419 aula t√° chata, s√≥ lendo sobre...\n",
       "19     @iasminleao_ o pastel eu n√£o tenho, mas a cala...\n",
       "20     @igorsenna97 eu paguei 13 num pastel min√∫sculo...\n",
       "21     @isecrf @empolguei domingo de manh√£, eu levant...\n",
       "22     @iviescopel caaaaaaaaaaaaaara! hj √© quinta! di...\n",
       "23     @jesmaciel @heitor147 eu ainda ia meter em esp...\n",
       "24     @joaopaulomf_ zerou a savassi gad kkkkkkkkk ma...\n",
       "25     @joomede79149855 tipo uma pastel e um caldo de...\n",
       "26     @lolozita17 muito pastel kkkkkk\\nagr bobagem s...\n",
       "27     @loremattitas @hiegofelipe nada de novo n√©, ca...\n",
       "28     @lucasalx97 to vendo mais sua m√£e do que voc√™ ...\n",
       "29                        @lucaszampiva1 pastel de chuva\n",
       "                             ...                        \n",
       "270               se tem uma coisa que eu gosto √© pastel\n",
       "271    sempre que saio do treino apetece-me pastel de...\n",
       "272    s√©rio, o de eu arranjo um pastel e uma pepsi a...\n",
       "273          s√≥ pelo meu pastelüòã https://t.co/putfm6yfj4\n",
       "274     s√≥ por desaforo vo bolar um pastel aq ü§§ kkkkkkkk\n",
       "275    s√≥ pq eu fiz a maior propaganda do pastel pra ...\n",
       "276    s√≥ queria comer 4 a√ßa√≠, 8 coxinha e 5 pastel c...\n",
       "277    s√≥ queria ir na escola pra depois sair e come ...\n",
       "278          s√≥ queria um pastel com caldo de cana agora\n",
       "279    so queria um pastel de frango com cheddar e mo...\n",
       "280    s√≥ quero um caldo de cana de 500ml, um pastel ...\n",
       "281    tentando entender pq eu comprei pipoca doce no...\n",
       "282    tfw ngm pra dormir cmg na sexta, acordar no s√°...\n",
       "283    t√¥ com uma vontade de comer pastel de carne co...\n",
       "284                   t√¥ doida pra comer um pastel pqp ü§§\n",
       "285    t√¥ na esperan√ßa de mam√£e ir na feira e trazer ...\n",
       "286    t√¥ nem entendendo essa vontade sendo que nem g...\n",
       "287                          todo mundo trouxe pastel hj\n",
       "288    tomei meu cafezinho com pastel, agora pode com...\n",
       "289    tudo que eu comi o dia todo hj foi um pastel c...\n",
       "290    uma tenta√ß√£o do cacete aqui em casa, to parand...\n",
       "291                        vai ter pastel pra lau amanh√£\n",
       "292            vei vontade de comer um pastel de 1 metro\n",
       "293    vi o v√≠deo da @nilmoretto comendo pastel e agr...\n",
       "294    vo s√≥ toma uma bera e v√™ o jogo.\\n\\n03:21 come...\n",
       "295               vou agitar o pastel essa hora da manh√£\n",
       "296    vou comer um pastel de frango com catupiry, n√£...\n",
       "297    vou flr cm vc l√° no pastel no s√°bado ‚Äî mds e q...\n",
       "298    vulneravel e fragilizado precisando comprar um...\n",
       "299                            ws ta vendendo pastel ü§£ü§£ü§£\n",
       "Name: Treinamento, Length: 300, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.Treinamento.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-fa27b327dabf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "data4 = cleanup(data3.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
