{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Projeto 2 - Ciência dos Dados\n",
    "\n",
    "Nome: Daniel Pucciariello\n",
    "\n",
    "Nome: Stephanie Liu\n",
    "\n",
    "A proposta desse trabalho é avaliar se um tweet sobre o tema \"Pastel\" foi feito por qual tipo de usuário: um usuário que gosta de Pastel e teve uma boa experiência decorrente do fato dele ter comido o alimento ou somente demonstra gostar desse, um usuário que desgoste de pastel ou teve uma má experiência ao se alimentar dele ou um usuário cujo emprego da palavra pastel tenha sido utilizada para expressar um sentimento que não se relacione com o alimento de forma direta (irrelevante).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n",
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "!pip install emoji\n",
    "!pip install preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import emoji\n",
    "import preprocessor as p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    punctuation = '[!-.:?;/]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    \n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    text_subbed=text_subbed.replace(\"\\n\", \" \")\n",
    "    text_subbed=text_subbed.replace(\"…\", \" \")\n",
    "    text_subbed=text_subbed.replace(\"@\", \" \")\n",
    "    text_subbed=text_subbed.replace(\"rt\", \"\")\n",
    "    text_subbed=text_subbed.replace(\"https\", \"\")\n",
    "    \n",
    "    return text_subbed\n",
    "#tirar coisas com https"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "# with open('auth.pass') as fp:    \n",
    "#     data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "# auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "# auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_treinamento = pd.read_excel(\"Excel_pastel.xlsx\",sheet_name=\"Treinamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevantes_raw = \" \".join(data_treinamento[data_treinamento.Classe<=1].Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevantes = cleanup(irrelevantes_raw)\n",
    "#irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relativa_ngostam_irrelevantes = pd.Series(irrelevantes.lower().split()).value_counts(True)\n",
    "tabela_absoluta_ngostam_irrelevantes = pd.Series(irrelevantes.lower().split()).value_counts(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gostam_raw = \" \".join(data_treinamento[data_treinamento.Classe==2].Treinamento)\n",
    "ngostam_raw = \" \".join(data_treinamento[data_treinamento.Classe<2].Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relativa_gostam = pd.Series(gostam_raw.lower().split()).value_counts(True)\n",
    "tabela_absoluta_gostam = pd.Series(gostam_raw.lower().split()).value_counts(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multiplicando_tabela_naogostam = tabela_relativa_ngostam_irrelevantes*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tudo=irrelevantes_raw + gostam_raw\n",
    "tudo=cleanup(tudo)\n",
    "tudo_absoluto=pd.Series(tudo.lower().split()).value_counts(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_teste = pd.read_excel(\"Excel_pastel.xlsx\",sheet_name=\"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tudo_raw = tudo.split()\n",
    "tudo_sem_repeticao = set(tudo_raw)\n",
    "\n",
    "#tudo_sem_repeticao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:851: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'valor_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c0ea87f693d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mvalor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabela_absoluta_gostam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mvalor_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mlista\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m#print(valor_a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valor_a' is not defined"
     ]
    }
   ],
   "source": [
    "#data_teste_idx= data_teste.set_index(\"Teste\")\n",
    "# vamos ter a nossa string relevante e string de não relevante\n",
    "# vamos somar os dois = total\n",
    "# vamos dar o split = lista total\n",
    "# vamos jogaar a lista total no set --> conjunto de palavras unicas\n",
    "# ao temos o len do set  -- numero das palavras unicas\n",
    "\n",
    "# ao inves da freq relativa \n",
    "\n",
    "#     gosta=((tabela_absoluta_gostam[i.split()]+1)/(count_palavras_gostam+d)).prod()\n",
    "#     ngosta=((tabela_absoluta_ngostam_irrelevantes[i.split()]+1)/(count_palavras_gostam+d)).prod()\n",
    "lista=[]\n",
    "\n",
    "#Variaveis gostam \n",
    "gostam_limpo = cleanup(gostam_raw)\n",
    "palavras_gostam = gostam_limpo.split()\n",
    "ngostam_limpo = cleanup(ngostam_raw)\n",
    "\n",
    "#Variaveis que não gostam\n",
    "palavras_ngostam = ngostam_limpo.split()\n",
    "count_palavras_gostam = len(palavras_gostam)\n",
    "count_palavras_ngostam = len(palavras_ngostam)\n",
    "\n",
    "d = len(tudo_sem_repeticao)\n",
    "\n",
    "#fazer if pra verificar se a palavra eh inedita ou nao; se for inedita, vai ser igual ao termo abaixo\n",
    "\n",
    "n_existe = 1/(count_palavras_gostam+d)\n",
    "\n",
    "#se der underflow, tem que fazer log \n",
    "for i in data_teste.Teste:\n",
    "    gosta = 1\n",
    "    ngosta = 1\n",
    "    for x in i.split():\n",
    "        prob_g = 0\n",
    "        prob_n = 0\n",
    "        if x not in tabela_absoluta_gostam:\n",
    "            prob_g= 1/(count_palavras_gostam+d)\n",
    "            \n",
    "        elif x in tabela_absoluta_gostam:\n",
    "            prob_g=((tabela_absoluta_gostam[x]+1)/(count_palavras_gostam+d))\n",
    "            \n",
    "        if x not in tabela_absoluta_ngostam_irrelevantes:\n",
    "            prob_n= 1/(count_palavras_ngostam+d)\n",
    "            \n",
    "        elif x in tabela_absoluta_ngostam_irrelevantes:\n",
    "            prob_n=((tabela_absoluta_ngostam_irrelevantes[x]+1)/(count_palavras_ngostam+d))\n",
    "            \n",
    "        gosta*=prob_g\n",
    "        ngosta*=prob_n\n",
    "    \n",
    "    if gosta>ngosta:\n",
    "        valor=2\n",
    "    elif gosta<ngosta:\n",
    "        valor=1\n",
    "    a = tabela_absoluta_gostam[i.split()]+1\n",
    "    valor_a.append(a)\n",
    "    lista.append(valor)\n",
    "#print(valor_a)\n",
    "\n",
    "data_teste.Classe = lista\n",
    "data_teste\n",
    "data_teste.to_excel(\"Classificador_3_categ_v1.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errou=len(data_teste.loc[(data_teste.Classe==2)&(data_teste.Modelo<=1)])\n",
    "acuracia=1-(errou/(len(data_teste)))\n",
    "acuracia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
